---
title: "Regresión múltiple y otras técnicas multivariadas"
subtitle: "Proyecto Final"
author:
  - "Rivera Torres Francisco de Jesús"
  - "Rodríguez Maya Jorge Daniel"
  - "Samayoa Donado Víctor Augusto"
  - "Trujillo Barrios Georgina"
date: "Junio  04, 2019"
output:
  pdf_document:
    toc: false
    number_sections: false
    fig_caption: true
    highlight: kate
    df_print: kable
    includes:
      in_header: tex/header.tex
fontsize: 12pt
documentclass: article
classoption: twoside
fig_align: "center"
---

```{r setup, include = FALSE, eval = TRUE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, fig.height = 3)

# Se cargan las librerias a utilizar
library(leaps)
library(MASS)
library(tidyverse)
library(readxl)
library(scales)
library(grid)
library(kableExtra)
library(latex2exp)
library(ggcorrplot)

datos_path <- "datos/"
```

# Introducción

Aqui ponemos la motivación...

La variable objetivo es inversión extranjera

# Análisis exploratorio

A continuación se realiza el análisis exploratorio de los datos para observar y comprender de mejor forma el comportamiento de estos, así como para poder visualizar datos a típicos o que sean influyentes. Para ello comenzaremos por realizar las gráficas box-plot  las cuales nos permiten distinguir los rangos y las distribuciones de cada una de las variables.

```{r}
datos <- paste0(datos_path, "ciudades.csv") %>% 
         read_csv(col_types = cols(.default = col_double(),
                                    ciudad = col_character(),
                                    diversif_econ = col_integer()
                                   )
                  ) %>% 
         select(-ciudad)
```

Generamos las gráficas boxplot para comprender los rangos y distribuciones de cada una de las variables:

```{r, fig.height = 9}
datos %>% 
  gather(key = variable, value = medicion) %>% 
  ggplot(aes(x = 0, y = medicion)) +
  geom_boxplot(outlier.colour = "firebrick") +
  facet_wrap(vars(variable), scales = "free", ncol = 3) +
  labs(title = "Diagramas de boxplot",
       y = "Valores") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_blank(),
        axis.title.x = element_blank())
```

Con estas gráficas podemos apreciar que ciertas variables parecen tener una distribución bastante simétrica, sin embargo en algunos casos se muestran variables que presentan un notable sesgo a la derecha y algunos outliers. Los casos más notables de estas son:

- Desastres
- Inversión extranjera
- Muertes de infantes
- PIB
- Robo de mercancias
- Tarjetas de débito y crédito


La variable desastres agrupa la mayor parte de los datos en un rango de cero a cinco y presenta algunos valores extremos que llegan al rango de 15. 

Inversión extranjera, es una de las variables que presentan un sesgo notorio, donde los datos están en su mayor parte concentrados alrededor del cero.

Muerte de infantes, PIB, robo de mercancías y tarjetas de débito y crédito, son otras de las variables que presentan un sesgo y en todos los casos también presentan valores extremos.

Hay algunas otras variables que aparentemente tienen un comportamiento simétrico, pero que también presentan valores extremos que deben tomarse en cuenta, como son `diversif_econ` o `esc_buenDesempeno`.

Como se está haciendo el análisis general de los datos para tratar de explicar la inversión extranjera en términos de las otras variables, el análisis exploratorio de las boxplot, nos muestra, como era de esperarse, que algunas variables tendrán un mayor efecto en el comportamiento de nuestra variable objetivo, pero también nos alerta de dar un tratamiento adecuado para evitar que las variables influyentes que se observan puedan sesgar los resultados, esto se tomará en cuenta más adelante en el tratamiento de los datos.

Para visibilizar mejor el comportamiento de las variables que presentan un sesgo elaboramos sus histogramas.

```{r}
datos %>% 
  select(desastres, inversion_extranjera, muerte_infIntes, pib, robo_mercancias, tarjetasDebCred) %>% 
  gather(key = variable, value = medicion) %>% 
  ggplot(aes(x = medicion)) +
  geom_histogram(bins = 35) +
  facet_wrap(vars(variable), scales = "free", ncol = 3) +
  labs(title = "Histogramas para las variables sesgadas a la derecha",
       y = "Conteo") +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_blank(),
        axis.title.x = element_blank())
```

En efecto, en los histogramas anteriores, podemos apreciar que hay un sesgo positivo en estas variables.

Ahora analizaremos las correlaciones entre los pares de variables.


```{r, fig.height = 4.5}
datos %>%
  cor() %>% 
  ggcorrplot(method = "square", type = "upper", colors = c("firebrick", "white", "steelblue"))
```

En la gráfica anterior se aprecia que las variables con más alta correlación son el PIB con inversion_extranjera, por lo que resulta conveniente hacer un diagrama de dispersión para estas variables para estudiar su comportamiento.

```{r}
datos %>% 
  ggplot(aes(x = pib, y = inversion_extranjera)) +
  geom_point() +
  labs(title = "Inversión extranjera contra PIB",
       x = "PIB",
       Y = "Inversión extranjera") +
  theme(plot.title = element_text(hjust = 0.5))
```

Podemos notar que la inversión extranjera se concentra en torno del origen, salvo para dos valores extremos, después de revisar los datos encontramos que estos valores corresponden a la Ciudad de México y a la ciudad de Monterrey, son valores extremos o palanca que influyen en el comportamiento de los datos, haciendo de esta manera que los datos estén mayormente correlacionados de forma positiva. 

# Selección de modelos

Una vez se tiene un panorama del comportamiento de los datos, procedemos a generar modelos que nos ayuden a explicar la **inversion extranjera**.

## Modelo 1

Ajustamos un modelo utilizando todas las variables para tener una punto de referencia del nivel de significancia del modelo y cuál es la máxima varianza que se puede explicar.

```{r}
datos1 <- datos

modelo1 <- datos1 %>% 
           lm(formula = inversion_extranjera ~ .)

summary(modelo1)
```

## Modelo 2

Debido a que son muchas variables, decidimos utilizar la selección en ambas direcciones para seleccionar un subconjunto de variables para el modelo.

```{r}
# fit.null <- lm(inversion_extranjera ~ 1, data = datos)
# 
# fit.full <- lm(inversion_extranjera ~ ., data = datos)
# 
# fit.both <- stepAIC(fit.null, direction = 'both',
#                     scope = list(lower = fit.null, upper = fit.full))

datos2 <- datos %>% 
          select(inversion_extranjera, pib, empl_formales, ingresos_propios, tarjetasDebCred,
                 percepcionSeguridad, diversif_econ, gini_salarial, desastres)

modelo2 <- datos2 %>% 
       lm(formula = inversion_extranjera ~ .)

summary(modelo2)
```


# Validación de supuestos y acciones correctivas

En esta sección se procede a validar los supuestos correspondientes a los modelos de regresión lineal múltiple (RLM).

## Linealidad

Sabemos que uno de los supuestos de los modelos de RLM es que la variable a explicar tenga una distribución normal alderedor del valor esperado por el modelo ajustado.
\begin{align*}
\mathrm{E} (Y_i | \mathrm{x}_i) &= \mathrm{x}_i^T \beta, \qquad i = 1, \ldots, n
\end{align*}

### Modelos 1

Para revisar si se cumple el supuesto de linealidad, se procede a graficar los residuos del modelo respecto a cada una de las variables explicativas.

```{r, fig.height = 9}
datos1 %>% 
  mutate(residuos = modelo1$residuals) %>% 
  gather(key = variable, value = medicion, -c(residuos, inversion_extranjera)) %>% 
  ggplot(aes(x = medicion, y = residuos)) +
  geom_point() +
  facet_wrap(vars(variable), scale = "free", ncol = 3) +
  labs(title = "Validación del supuesto de linealidad modelo 1",
       x = "Variable explicativa",
       y = "Residuos") +
  theme(plot.title = element_text(hjust = 0.5))
```

En la gráfica anterior se observa que las variables `pib` y `reobo_mrecancia` contienes datos atípicos, lo que no permite apreciar de forma adecuada si hay o no un patrón en las gráficas de residuos contra dichas variables.

Respecto a la variable desastres, se determina eliminarla. Esto debido a que todos son valores enteros y no preserva la linealidad.

Se procede a aplicar la transformación logaritmo a las variables explicativa `pib` y `robo_mercancias` y se ajusta nuevamente el modelo con todas las variables.

```{r}
datos1 <- datos1 %>% 
          mutate(log_inversion_extranjera = log(inversion_extranjera),
                 pib_log = log(pib),
                 robo_mercancias_log = log(robo_mercancias)) %>% 
           select(-c(inversion_extranjera, pib, robo_mercancias, desastres))

modelo1 <- datos1 %>% 
           lm(formula = log_inversion_extranjera ~ .)

summary(modelo1)
```

Se procede a analizar nuevamente el comportamiento del residuo para este nuevo ajuste respecto a cada una de las variables explicativas.

```{r, fig.height = 9}
datos1 %>% 
  mutate(residuos = modelo1$residuals) %>% 
  gather(key = variable, value = medicion, -c(residuos, log_inversion_extranjera)) %>% 
  ggplot(aes(x = medicion, y = residuos)) +
  geom_point() +
  facet_wrap(vars(variable), scale = "free", ncol = 3) +
  labs(title = "Validación del supuesto de linealidad modelo 1",
       x = "Variable explicativa",
       y = "Residuos") +
  theme(plot.title = element_text(hjust = 0.5))
```

Como puede apreciarse en el gráfico anterior los residuos no tienen patrones respecto a las variables explicativas. Por lo que concluimos que las transformaciones realizadas tanto en la varaible objetivo como en las variables explicativas permiten cumplir el supuesto de linealidad.

### Modelo 2

Para revisar si se cumple el supuesto de linealidad, se procede a graficar los residuos del modelo respecto a cada una de las variables explicativas.

```{r, fig.height = 4.5}
datos2 %>% 
  mutate(residuos = modelo2$residuals) %>% 
  gather(key = variable, value = medicion, -c(residuos, inversion_extranjera)) %>% 
  ggplot(aes(x = medicion, y = residuos)) +
  geom_point() +
  facet_wrap(vars(variable), scale = "free", ncol = 3) +
  labs(title = "Validación del supuesto de linealidad modelo 2",
       x = "Variable explicativa",
       y = "Residuos") +
  theme(plot.title = element_text(hjust = 0.5))
```

En este caso se procederá de manera análoga al modelo anterior eliminando la variable desastres y aplicando la transformación de logaritmo tanto a `inversión_extranjera` y a `pib`.

```{r}
datos2 <- datos2 %>% 
          mutate(log_inversion_extranjera = log(inversion_extranjera),
                 pib_log = log(pib)) %>% 
           select(-c(inversion_extranjera, pib, desastres))

modelo2 <- datos2 %>% 
           lm(formula = log_inversion_extranjera ~ .)

summary(modelo2)
```

Se procede a analizar nuevamente el comportamiento del residuo para este nuevo ajuste respecto a cada una de las variables explicativas.

```{r, fig.height = 4.5}
datos2 %>% 
  mutate(residuos = modelo2$residuals) %>% 
  gather(key = variable, value = medicion, -c(residuos, log_inversion_extranjera)) %>% 
  ggplot(aes(x = medicion, y = residuos)) +
  geom_point() +
  facet_wrap(vars(variable), scale = "free", ncol = 3) +
  labs(title = "Validación del supuesto de linealidad modelo 2",
       x = "Variable explicativa",
       y = "Residuos") +
  theme(plot.title = element_text(hjust = 0.5))
```

Como puede apreciarse en el gráfico anterior los residuos no tienen patrones respecto a las variables explicativas. Por lo que concluimos que las transformaciones realizadas tanto en la varaible objetivo como en las variables explicativas permiten cumplir el supuesto de linealidad.

## Homocedasticidad

Para este supuesto debemos revisar que la varianza es constante
\begin{align*}
\mathrm{V} (Y_i | \mathrm{x}_i) &= \sigma^2, \qquad i = 1, \ldots, n
\end{align*}

### Modelo 1


### Modelo 2


## No correlación

Generamos el diagrama de dispersión
\begin{align*}
\mathrm{Cor} (Y_i, Y_j | \mathrm{x}_i, \mathrm{x}_j) = 0, \qquad i, j = 1, \ldots, n, \qquad i\neq j
\end{align*}

### Modelo 1


### Modelo 2

## Supuesto de normalidad

En ambos modelos, la variable a explicar es la inversión extranjera, por lo que se procede acomparar la distribución de dicha varaible y su transformación `log(inversion extranjera)`. Debido a que ya habíamos observado que dicha varaible tenía un sesgo hacia la derecha.

```{r}
datos %>% 
  mutate(log_inversion_extranjera = log(inversion_extranjera)) %>% 
  gather(key = variable, value = medicion, c(log_inversion_extranjera, inversion_extranjera)) %>% 
  ggplot(aes(x = medicion)) +
  geom_density() +
  facet_wrap(vars(variable), scales = "free") +
  labs(title = "Comparación entre la variable original y su transformación",
       x = "Valor",
       y = "Densidad") +
  theme(plot.title = element_text(hjust = 0.5))
```

En la gráfica anteriro se puede apreciar que al aplicarle logaritmo a la variable se obtiene una forma más simétrica. Por lo que procedemos a realizar la comparación en la gráfica QQ-norm para determianr qué tato se aproxima a una distrbución normal.

```{r}
media <- mean(datos1$log_inversion_extranjera)
desv_st <- sd(datos1$log_inversion_extranjera)

datos %>% 
  mutate(log_inversion_extranjera = log(inversion_extranjera)) %>% 
  gather(key = variable, value = medicion, c(log_inversion_extranjera, inversion_extranjera)) %>% 
  ggplot(aes(sample = medicion)) +
  stat_qq(dparams = list(mean = media, sd = desv_st)) +
  stat_qq_line(dparams = list(mean = media, sd = desv_st)) +
  facet_wrap(vars(variable), scales = "free") +
  labs(title = "Gráficas QQ-Norm",
       x = "Distribución teórica",
       y = "Datos observados") +
  theme(plot.title = element_text(hjust = 0.5))
```

En este caso se logra apreciar que los datos transformados del logaritmo se ajustan mejor a una distribución normal con media $\mu = `r media`$ y desviación estandar $\sigma = `r desv_st`$.

Por tal motivo confirmamos que es necesario usar la transformación logaritmo de la varaible inversión extranjera.

## Modelo 1

Ahora procedemos a revisar la normalidad de los residuos para el primer modelo.

```{r}
desv_st <- sd(modelo1$residuals)

datos1 %>% 
  mutate(residuos = modelo1$residuals) %>% 
  ggplot(aes(sample = residuos)) +
  stat_qq(dparams = list(mean = 0, sd = desv_st)) +
  stat_qq_line(dparams = list(mean = 0, sd = desv_st)) +
  labs(title = "Gráficas QQ-Norm",
       x = "Distribución teórica",
       y = "Residuos") +
  theme(plot.title = element_text(hjust = 0.5))
```


## Modelo 2

Ahora procedemos a revisar la normalidad de los residuos para el primer modelo.

```{r}
desv_st <- sd(modelo2$residuals)

datos2 %>% 
  mutate(residuos = modelo2$residuals) %>% 
  ggplot(aes(sample = residuos)) +
  stat_qq(dparams = list(mean = 0, sd = desv_st)) +
  stat_qq_line(dparams = list(mean = 0, sd = desv_st)) +
  labs(title = "Gráficas QQ-Norm",
       x = "Distribución teórica",
       y = "Datos observados") +
  theme(plot.title = element_text(hjust = 0.5))
```

## Análisis de multicolinealidad

Con base en el análisis exploratorio de los datos, sabemos que las correlaciones por pares entre las variables explicativas es baja. Sin embargo, es util obtener el índice de condición $\kappa$ para tener un criterio cuantitativo sobre el nivel de colinealidad que existe entre las variables explicativas.

### Modelo 1

En este caso se procede a calcular la $\kappa$ para la matríz de variables explicativas:

- esc_buenDesempeno.
- mortalidad_infantil.
- tasa_suicidios.
- muerte_infIntes.
- empl_formales.
- densidad_pobl.
- sal_trabTiemCompl.
- gini_salarial.
- diversif_econ.
- desempleo.
- tarjetasDebCred.
- ingresos_propios.
- percepcionSeguridad.
- vivendas_deshabitadas.
- empresas.
- log_pib.
- log_robo_mercancias.

```{r}
kappa1 <- datos1 %>% 
  select(-log_inversion_extranjera) %>% 
  as.matrix() %>% 
  kappa
```

obteniendo así un valor de $\kappa_1 = `r kappa1`$.

### Modelo 2

En este caso se procede a calcular la $\kappa$ para la matríz de variables explicativas:

- empl_formales.
- ingresos_propios.
- tarjetasDebCred.
- percepcionSeguridad.
- diversif_econ.
- gini_salarial.
- log_inversion_extranjera.
- pib_log

```{r}
kappa2 <- datos2 %>% 
  select(-log_inversion_extranjera) %>% 
  as.matrix() %>% 
  kappa
```

obteniendo así un valor de $\kappa_2 = `r kappa2`$.

# Análisis de observaciones atípicas y observaciones influyentes

A continuación procedemos a analizar los datos atípicos y las observaciones influyentes que observamos en los datos tanto en el análsisi exploratorio como en el análisis de validación de supuestos.

### Modelo 1

En este modelo notamos que variables como el PIB tenían datos influyentes, principalemte el datos más extremo asociado al valle de México. Por lo que se decidió aplicar una transformación logaritmo para minizar dicho efecto y no tener que eliminarlos del análisis.

```{r}
datos1 %>% 
  ggplot(aes(x = pib_log, y = log_inversion_extranjera)) +
  geom_point() +
  labs(title = "Log(Inversión extranjera) contra Log(PIB)",
       x = "Log(PIB)",
       Y = "Log(Inversión extranjera)") +
  theme(plot.title = element_text(hjust = 0.5))
  
```

### Modelo 2

En este modelo también se tiene la variable PIB con explicativa, por lo que se procede a realizar la misma tranformación al PIB y se vuelve a ajustar el modelo.

# Análisis del modelo final

De acuerdo con el análisis previo, se decidió elegir el modelo 2. A partir del cual podemos realizar las siguientes interpretaciones.

```{r}
betas <- coefficients(modelo2)
```

El interceptó es $\beta_0 = `r betas[0 + 1]`$ quiere decir que si las demás variables tomarán un valor de cero la inversión extranjera sería negativa lo cual no es interpetable pues la inversión sólo puede ser mayor o igual a cero.

Por parte de los coeficientes

- $\beta_1 = `r betas[1 + 1]`$ la inversión extranjera crece 0.000001963 unidades por cada unidad que aumenta el pib.
- $\beta_2 = `r betas[2 + 1]`$ la inversión extranjera crece 37.36 unidades por cada unidad que aumentan los empleos formales.
- $\beta_3 = `r betas[3 + 1]`$ la inversión extranjera crece 442.6 unidades por cada unidad que aumentan los ingresos propios.
- $\beta_4 = `r betas[4 + 1]`$ la inversión extranjera decrece 37.67 unidades por cada unidad que aumentan las tarjetas de débito credito.
- $\beta_5 = `r betas[5 + 1]`$ la inversión extranjera decrece 265.8 unidades por cada unidad que aumentan la percepción de la seguridad.
- $\beta_6 = `r betas[6 + 1]`$ la inversión extranjera decrece .3028 unidades por cada unidad que aumentan la diversificación economica.
- $\beta_7 = `r betas[7 + 1]`$ la inversión extranjera crece 699.7 unidades por cada unidad que aumentan los gini salarial.
- $\beta_8 = `r betas[8 + 1]`$ la inversión extranjera crece 2.449 unidades por cada unidad que aumentan los desastres.
