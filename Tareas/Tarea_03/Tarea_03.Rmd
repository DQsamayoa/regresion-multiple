---
title: "Regresión múltiple y otras técnicas multivariadas"
subtitle: "Tarea 03"
author:
  - "Rivera Torres Francisco de Jesús"
  - "Rodríguez Maya Jorge Daniel"
  - "Samayoa Donado Víctor Augusto"
  - "Trujillo Barrios Georgina"
date: "Febrero 27, 2019"
output:
  pdf_document:
    toc: false
    number_sections: false
    fig_caption: true
    highlight: tango
    df_print: kable
    includes:
      in_header: tex/header.tex
fontsize: 11pt
documentclass: article
classoption: twoside
fig_align: "center"
---

```{r setup, include = FALSE, eval = TRUE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, fig.height = 5)

# Se cargan las librerias y los datos que se utilizarán
library(tidyverse)
library(readxl)
library(scales)
library(grid)
library(kableExtra)
library(latex2exp)
ingresos <- read.table("01datos/ejemplo_ingresoporhora.csv", header = TRUE, sep = ",")
```

#Ejercicio 1
Suponer que se ajusta un modelo RLS a las observaciones $(x_i, y_i)$ con $i=1,\cdots, n$. Mostrar que

\begin{align*}
SCE= \frac{S_{xx} S_{yy}- S^2_{xy}}{S_{xx}}
\end{align*}

Donde:
\begin{itemize}
\item $SCE= \displaystyle\sum_i^n(y_i-\hat\beta_0-\hat\beta_1x_i) ^2$
\item $S_{yy}= \displaystyle\sum_i^n(y_i-\bar{y_n})^2$
\end{itemize}

Entonces:

\begin{equation}
    \begin{split}
    \notag SCE &= \sum_{i=1}^{n} \left( y_i-\bar{\beta}_0-\bar{\beta}_1x_i \right)^2 = \sum_{i=1}^{n} \left( y_i-\left( \bar{y}_n-\frac{S_{xy}\bar{x}_n}{S_{xx}} \right)-\frac{S_{xy}}{S_{xx}}x_i \right)^2 = \sum_{i=1}^{n} \left( y_i-\bar{y}_n+\frac{S_{xy}\bar{x}_n-S{xy}x_i}{S_xx} \right)^2\\
    &= \sum_{i=1}^{n} \left( \left( y_i-\bar{y}_n \right)-\frac{S{xy}\left( x_i-\bar{x}_n \right)}{S{xx}} \right)^2 = \sum_{i=1}^{n} \left( \left( y_i-\bar{y}_n \right)^2-2\left( y_i-\bar{y}_n \right)\left( x_i-\bar{x}_n \right)\frac{S_{xy}}{S_{xx}}+\frac{S{xy}^2\left( x_i-\bar{x}_n \right)^2}{S_{xx}^2} \right)\\
    &= \sum_{i=1}^{n}\left( y_i-\bar{y}_n \right)^2-2\frac{S_{xy}}{S_{xx}}\sum_{i=1}^{n}\left( y_i-\bar{y}_n \right)\left( x_i-\bar{x}_n \right)+\frac{S_{xy}^2}{S_{xx}^2}\sum_{i=1}^{n}\left( x_i-\bar{x}_n \right)^2 = S_{yy}-2\frac{S_{xy}S_{xy}}{S_{xx}}+\frac{S_{xy}^2S_{xx}}{S_{xx}^2}\\
    &= S_{yy}-2\frac{S_{xy}^2}{S_{xx}}+\frac{S_{xy}^2}{S_{xx}} = \frac{S_{xx}S_{yy}-2S_{xy}^2+S_{xy}^2}{S_{xx}} = \frac{S_{xx}S_{yy}-S_{xy}^2}{S_{xx}}
    \end{split}
    \end{equation}
    
Por lo tanto

\begin{equation}
    \begin{split}
    \notag SCE = \frac{S_{xx}S_{yy}-S_{xy}^2}{S_{xx}}
    \end{split}
    \end{equation}

#Ejercicio 2
Mostrar la desigualdad de Bonferroni. Si $E_1,\ldots , E_k$ son eventos en un espacio de probabilidad
$(\Omega, A, P)$ entonces:
\begin{align*}
P\left(\bigcap\limits_{i = 1}^k E_i \right) \geqslant 1- \sum_{i = 1}^k P(\Omega \setminus E_i) 
\end{align*}

\begin{proof}
La demostración se realizará por inducción sobre el número de eventos en un espacio de probabilidad.

Base: k = 1
\begin{align*}
P(\Omega) &= 1, \qquad \text{pero } \Omega = E \cup \left(\Omega \setminus E_1\right) \text{, entonces} \\
P(E \cup \left(\Omega \setminus E_1\right)) &= P(E_1) + P(\Omega \setminus E_1) = 1, \qquad \text{ya que son probabilidades mutuamente excluyentes} \\
P(E_1) &= 1 -  P(\Omega \setminus E_1), \qquad \ \text{como se da la igualdad entonces tambien se satisface que} \\
P(E_1) &\geqslant 1 -  P(\Omega \setminus E_1)
\end{align*}

Ahora, por hipótesis de inducción, suponemos que se vale para $n$ eventos en el espacio de probabilidad, por lo que se satisface la desigualdad
\begin{align*}
P\left(\bigcap\limits_{i = 1}^n E_i \right) \geqslant 1- \sum_{i = 1}^n P(\Omega \setminus E_i) 
\end{align*}
Y procedemos a demostrar que siempre que se cumpla para $n$ eventos, se debe de cumplir para $n + 1$ eventos.

\begin{align*}
P\left(\bigcap\limits_{i = 1}^{n + 1} E_i \right)
&= P \left( \left( \bigcap\limits_{i = 1}^{n} E_i) \right) \bigcap E_{n + 1} \right) \\
&= P \left( \bigcap\limits_{i = 1}^{n} E_i) \right) + P \left( E_{n + 1} \right) - P \left( \left( \bigcap\limits_{i = 1}^{n} E_i) \right) \bigcup E_{n + 1} \right)
\end{align*}
Pero notemos que $P \left( \left( \bigcap_{i = 1}^{n} E_i) \right) \bigcup E_{n + 1} \right) \leqslant 1$, por lo que $ - P \left( \left( \bigcap_{i = 1}^{n} E_i) \right) \bigcup E_{n + 1} \right) \geqslant -1$, entonces
\begin{align*}
P\left(\bigcap\limits_{i = 1}^{n + 1} E_i \right)
&\geqslant P \left( \bigcap\limits_{i = 1}^{n} E_i) \right) + P \left( E_{n + 1} \right) - 1 \\
&\text{aplicando la hipótesis de inducción, se tiene} \\
&\geqslant 1- \sum_{i = 1}^n P(\Omega \setminus E_i)  + P \left( E_{n + 1} \right) - 1 \\
&\geqslant 1- \sum_{i = 1}^n P(\Omega \setminus E_i)  + \left(1 - P \left(\Omega \setminus E_{n + 1} \right) \right) - 1 \\
&\geqslant 1- \sum_{i = 1}^n P(\Omega \setminus E_i)  + P \left(\Omega \setminus E_{n + 1} \right) \\
&\geqslant 1- \sum_{i = 1}^{n + 1} P(\Omega \setminus E_i)
\end{align*}
\end{proof}


#Ejercicio 3
Considerar los datos de ingreso y escolaridad utilizados en los ejemplos de intervalos de confianza
de las notas. Reportar intervalos simultáneos de confianza $95\%$ para las medias del ingreso por
hora para $9$, $15$ y $19$ años de escolaridad a) con el método de Bonferroni y b) con el método de
Hotelling$-$Scheffé

# Ejercicio 4
El conjunto de datos `airquality`, de paquete datasets de R contiene información sobre la calidad
del aire en Nueva York registrada de Mayo a Septiembre de $1973$ (se pude consultar más información
con el comando `help("airquality")`. Para responder este ejercicio, descartar las observaciones con
valores perdidos.

## Inciso 4.a
Ajustar un modelo RLS para explicar el nivel de ozono como función del $log_2$ de la velocidad
del viento. Reportar las estimaciones de los parámetros.

```{r, echo = TRUE}
library(tidyverse)

modelo_air <- airquality %>% 
              as_tibble() %>% 
              filter(!is.na(Ozone), !is.na(Wind)) %>% 
              mutate(log2_Wind = log2(Wind)) %>% 
              lm(formula = Ozone ~ log2_Wind)

coefficients(modelo_air)
```

## Inciso 4.b
Mostrar una gráfica de dispersión de los datos utilizados para ajustar el modelo del inciso
anterior, la recta de regresión ajustada y bandas de confianza $95\%$. Anexar el código relacionado
con el cómputo de las bandas de confinza.

```{r, echo = TRUE}
# Código para el cálculo de los intervalos de confianza para el módelo RLS
bandas_confianza_rls <- function(datos, formula_rls, alpha = 0.95) {
  # Función que calcula las bandas de confianza para el modelo RLS
  # usando el método de Hotelling-Scheffé
  
  datos <- datos %>% 
           as_tibble()
  
  # Se extrae la variable independiante (X) de la formula de RLS
  variable_x <- formula_rls[[3]] 
  variable_x <- enquo(variable_x)
  
  # Se calcula el modelo RLS
  modelo <- datos %>% 
            lm(formula = formula_rls)
  
  # estimador de beta0
  b0.hat <- coefficients(modelo)[1] 
  
  # estimador de beta1
  b1.hat <- coefficients(modelo)[2] 
  
  # estimador sigma2
  s2.hat <- (summary(modelo)$sigma)^2
  
  # Se calculan las bandas de confianza
  resultado <- datos %>% 
               mutate(# Se obtienen el número de observaciones
                      n = n(),
                      # Se obtiene el quantil de la distribución F(2, n - 2),
                      # con un nivel de confianza alpha
                      fa = qf(alpha, 2, n - 2),
                      # Se calcula la estimación de y
                      y.hat = b0.hat + b1.hat * !! variable_x,
                      # Se calcula la media x
                      x.bar = mean(!! variable_x),
                      # Se calcula la varianza de x
                      S.xx = sum((!! variable_x - mean(!! variable_x))^2),
                      # Se calculan los límites de la banda de confianza
                      banda_superior = y.hat + sqrt(2*fa*s2.hat)*
                                    sqrt(1/n + (!! variable_x-x.bar)^2/S.xx),
                      banda_inferior = y.hat - sqrt(2*fa*s2.hat)*
                                    sqrt(1/n + (!! variable_x-x.bar)^2/S.xx)) %>% 
               select(-c(n, fa, x.bar, S.xx))
  
  return(resultado)
}
```

A contunación se muestra la tabla con los resultados de $\hat{y}$ y los límites inferior y superior de la banda de confianza para el modelo RLS.

```{r, echo = TRUE, eval = FALSE}
airquality %>% 
  as_tibble() %>% 
  select(Ozone, Wind) %>% 
  filter(!is.na(Ozone), !is.na(Wind)) %>% 
  mutate(log2_Wind = log2(Wind)) %>% 
  bandas_confianza_rls(formula_rls = Ozone ~ log2_Wind)
```

```{r}
airquality %>% 
  as_tibble() %>% 
  select(Ozone, Wind) %>% 
  filter(!is.na(Ozone), !is.na(Wind)) %>% 
  mutate(log2_Wind = log2(Wind)) %>% 
  bandas_confianza_rls(formula_rls = Ozone ~ log2_Wind) %>% 
  knitr::kable(format = "latex", booktabs = TRUE, longtable = TRUE, linesep = "",
               escape = FALSE, digits = 2,
               caption = "Estimaciones y bandas de confianza al 95\\%",
               col.names = c("Ozone", "Wind", "$\\log_2 (\\text{Wind})$",
                             "$\\widehat{\\text{Ozone}}$", "Inferior", "Superior")) %>% 
  row_spec(0, align = "c") %>% 
  add_header_above(c("", "", "", "", "Banda de confianza" = 2)) %>%
  kableExtra::kable_styling(latex_options = c("striped", "repeat_header"))
```

```{r}
airquality %>% 
  as_tibble() %>% 
  filter(!is.na(Ozone), !is.na(Wind)) %>% 
  mutate(log2_Wind = log2(Wind)) %>% 
  bandas_confianza_rls(formula_rls = Ozone ~ log2_Wind) %>% 
  ggplot(aes(x = log2_Wind)) +
  geom_point(aes(y = Ozone, color = "Observaciones")) +
  geom_line(aes(y = y.hat, group = 1, color = "Estimación")) +
  geom_ribbon(aes(ymin = banda_inferior, ymax = banda_superior), alpha = 0.3) +
  labs(title = TeX("Ozono vs $\\log_2 (Wind)$"),
       x = TeX("$\\log_2(Wind)$"),
       y = "Ozone") +
  scale_color_manual(values = c("Steelblue", "black")) +
  theme(plot.title = element_text(hjust = 0.5),
        legend.position = "top",
        legend.title = element_blank())
```


#Ejercicio 5
(Sheater) Un estadístico colaboró en un proyecto de investigación con dos entomólogos. El análisis
involucró el ajuste de modelos de regresión a grandes conjuntos de datos. Entre los tres escribieron
y sometieron un manuscrito a una revista de entomología. El escrito contenía varias gráficas de
dispersión mostrando la recta de regresión ajustada y las bandas de confianza $95\%$ para la verdadera recta de regresión calculadas con los IC individuales, así como los datos observados. Uno de los revisores del manuscrito hizo la siguiente observación:

No puedo entender cómo el $95\%$ de las observaciones cae fuera &nbsp;
 &nbsp; de las bandas de confianza $95\%$ que se muestran en las figuras

#Ejercicio 6

(Ross) Suponer que se tiene el siguiente conjunto de datos donde x representa la humedad de una
mezcla fresca de un determinado producto y y la densidad del producto terminado.

\begin{table}[]
\begin{tabular}{lllllllll}
x & 5   & 6   & 7    & 10   & 12   & 15   & 18   & 20   \\
y & 7.4 & 9.3 & 10.6 & 15.4 & 18.1 & 22.2 & 24.1 & 24.8
\end{tabular}
\end{table}

Ajustar un modelo RLS a los datos anteriores y responder lo siguiente.

## Inciso 6.a
Reportar la estimación puntual de $\sigma^2$ e interpretar el resultado en cuanto a la utilidad del
modelo RLS ajustado.

## Inciso 6.b 
Reportar el IC $90\%$ para $\sigma^2$ con los cuantiles simétricos y su longitud.

## Inciso 6.c
Indicar cuáles son los cuantiles que proporcionan el IC $90\%$ para $\sigma^2$  de menor longitud.

## Inciso 6.d
Reportar el IC $90\%$ para $\sigma^2$ de menor longitud y compararlo con el intervalo del inciso
$a$).
